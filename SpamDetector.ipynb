{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoRBsiA6dUuj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = pd.read_csv(\"spam.csv\", encoding=\"latin-1\")[[\"v1\", \"v2\"]]\n",
        "data.columns = [\"label\", \"message\"]\n",
        "\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "Vgvjsi6deF_j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f61a9028-eaae-4200-b33c-da760feb7a52"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                            message\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Manual stopwords list (offline-friendly)\n",
        "stop_words = set([\n",
        "    \"i\",\"me\",\"my\",\"we\",\"our\",\"you\",\"your\",\"he\",\"she\",\"it\",\"they\",\"this\",\n",
        "    \"that\",\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"have\",\"has\",\"do\",\"does\",\"a\",\"an\",\"the\",\n",
        "    \"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\n",
        "    \"about\",\"against\",\"between\",\"into\",\"through\",\"during\",\"before\",\"after\",\n",
        "    \"above\",\"below\",\"to\",\"from\",\"in\",\"out\",\"on\",\"off\",\"over\",\"under\",\"again\",\"further\",\n",
        "    \"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\"each\",\n",
        "    \"few\",\"more\",\"most\",\"other\",\"some\",\"such\",\"no\",\"nor\",\"not\",\"only\",\"own\",\"same\",\n",
        "    \"so\",\"than\",\"too\",\"very\",\"can\",\"will\",\"just\",\"should\",\"now\"\n",
        "])\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    words = text.split()\n",
        "    words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "data[\"cleaned\"] = data[\"message\"].apply(clean_text)\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "8f4JZdTldbKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b1e72c-c3e4-4a05-a007-6e31242d4f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                            message  \\\n",
            "0   ham  Go until jurong point, crazy.. Available only ...   \n",
            "1   ham                      Ok lar... Joking wif u oni...   \n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
            "3   ham  U dun say so early hor... U c already then say...   \n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
            "\n",
            "                                             cleaned  \n",
            "0  go jurong point crazi avail bugi n great world...  \n",
            "1                              ok lar joke wif u oni  \n",
            "2  free entri wkli comp win fa cup final tkt st m...  \n",
            "3                u dun say earli hor u c alreadi say  \n",
            "4          nah dont think goe usf live around though  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Feature extraction\n",
        "X = data[\"cleaned\"]\n",
        "y = data[\"label\"].map({\"ham\": 0, \"spam\": 1})  # encode labels\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=3000)\n",
        "X = vectorizer.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "yd70ZZtwdbHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train models\n",
        "# Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "nb_pred = nb_model.predict(X_test)\n",
        "\n",
        "# Logistic Regression\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_pred = lr_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "vb1YCuXrdbDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Evaluation\n",
        "print(\"Naive Bayes Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, nb_pred))\n",
        "print(confusion_matrix(y_test, nb_pred))\n",
        "print(classification_report(y_test, nb_pred))\n",
        "\n",
        "print(\"\\nLogistic Regression Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, lr_pred))\n",
        "print(confusion_matrix(y_test, lr_pred))\n",
        "print(classification_report(y_test, lr_pred))\n"
      ],
      "metadata": {
        "id": "hDXs7vM5ddlc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b6a156-c65d-4c5d-ea31-2bb5d94acbd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Results:\n",
            "Accuracy: 0.9766816143497757\n",
            "[[965   0]\n",
            " [ 26 124]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       965\n",
            "           1       1.00      0.83      0.91       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.99      0.91      0.95      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "\n",
            "Logistic Regression Results:\n",
            "Accuracy: 0.9524663677130045\n",
            "[[961   4]\n",
            " [ 49 101]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       965\n",
            "           1       0.96      0.67      0.79       150\n",
            "\n",
            "    accuracy                           0.95      1115\n",
            "   macro avg       0.96      0.83      0.88      1115\n",
            "weighted avg       0.95      0.95      0.95      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Save best model\n",
        "import joblib\n",
        "joblib.dump(lr_model, \"spam_model.pkl\")\n",
        "joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
        "print(\"Model and vectorizer saved!\")\n"
      ],
      "metadata": {
        "id": "rQlLI5CXddgv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa1870a5-9311-48d1-b497-fdbd7f9e8175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and vectorizer saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "28fbtFkupTQH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}